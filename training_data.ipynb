{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NoteBook train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T07:21:33.436329Z",
     "start_time": "2025-01-13T07:21:33.420471Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Dense, MaxPool2D, Conv2D, BatchNormalization, Dropout, Flatten,GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xử lý dữ liệu thô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã xử lý xong ảnh của: Hang với số ảnh: 500\n",
      "Đã xử lý xong ảnh của: Hieu với số ảnh: 500\n",
      "Đã xử lý xong ảnh của: Kien với số ảnh: 500\n",
      "Đã xử lý xong ảnh của: quan với số ảnh: 482\n",
      "Đã xử lý xong ảnh của: Thanh với số ảnh: 500\n",
      "Đã xử lý xong ảnh của: Tuan với số ảnh: 500\n",
      "Đã xử lý xong ảnh của: Viet Anh với số ảnh: 500\n",
      "Shape của data: (3482, 128, 128, 3) với các label {'Kien', 'quan', 'Hieu', 'Hang', 'Thanh', 'Tuan', 'Viet Anh'}\n"
     ]
    }
   ],
   "source": [
    "# Lấy thông tin các tệp con (trùng tên với label) trong tệp data_raw_image\n",
    "list_label = os.listdir('data_image_raw')\n",
    "\n",
    "# List lưu ảnh đã mã hóa và label tương ứng\n",
    "data_img = []\n",
    "label = []\n",
    "\n",
    "for item in list_label:\n",
    "    # Tạo dường dẫn đến từng tệp con (có thể dùng cộng xâu bth) cách bên dưới an toàn hơn\n",
    "    path_label = os.path.join('data_image_raw', item)\n",
    "    list_image = os.listdir(path_label) # Trả về tên các tệp ảnh\n",
    "    \n",
    "    for image in list_image:        # Tạo đường dẫn đến thư mục ảnh\n",
    "        path_image = os.path.join(path_label, image)\n",
    "        \n",
    "        # Đọc ảnh\n",
    "        matrix = cv2.imread(path_image)\n",
    "        \n",
    "        # Thêm ảnh và label tương ứng vào các list\n",
    "        data_img.append(matrix)\n",
    "        label.append(item)\n",
    "\n",
    "    # In ra màn thông báo\n",
    "    print(f'Đã xử lý xong ảnh của: {item} với số ảnh: {len(list_image)}')\n",
    "\n",
    "# Chuyển data và label về np.array vì tensorflow yêu cầu đầu vào là np.array, label cần đưa về dạng 2D\n",
    "data_img = np.array(data_img) \n",
    "cat_label = set(label.copy())\n",
    "label = np.array(label).reshape(-1, 1) # Có thể dùng expand_dim cũng được\n",
    "\n",
    "# Hiển thị ra màn console\n",
    "print(f'Shape của data: {data_img.shape} với các label {cat_label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lấy data từ file thư mục chứa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T10:16:02.371528Z",
     "start_time": "2025-01-12T10:16:02.293506Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encoder label\n",
    "encoder = OneHotEncoder(sparse_output= False)\n",
    "label_processed = encoder.fit_transform(label)\n",
    "# Chuẩn hóa data đầu vào\n",
    "data_processed = data_img.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3482, 128, 128, 3)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu categories lại vào file để tiện dùng lại để gán label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model/categories.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder.categories_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model/categories.pkl', 'rb') as f:\n",
    "    cat = pickle.load(f)\n",
    "\n",
    "lb = np.array(cat[0])\n",
    "\n",
    "num_class = lb.size # Số class dùng để phân biệt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chia tập train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T10:16:02.481412Z",
     "start_time": "2025-01-12T10:16:02.441100Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(data_processed, label_processed, test_size= 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tạo model và train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T10:16:02.676041Z",
     "start_time": "2025-01-12T10:16:02.519178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_22\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_22\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenet_1.00_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,228,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_23     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ mobilenet_1.00_128 (\u001b[38;5;33mFunctional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │     \u001b[38;5;34m3,228,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_23     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m903\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,360,967</span> (12.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,360,967\u001b[0m (12.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">132,103</span> (516.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m132,103\u001b[0m (516.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,228,864</span> (12.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,228,864\u001b[0m (12.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.applications import VGG16, EfficientNetB0, MobileNet\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load VGG16 without fully connected layers\n",
    "vgg = MobileNet(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "vgg.trainable = False\n",
    "# Đóng băng tất cả các tầng trước, sau đó mở khóa một số tầng cuối để fine-tune\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False  # Ban đầu đóng băng tất cả các tầng\n",
    "\n",
    "# Mở khóa một số tầng cuối để fine-tune (ví dụ, 4 tầng cuối)\n",
    "# for layer in vgg.layers[-1:]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "# Xây dựng mô hình mới\n",
    "model_cnn = Sequential([\n",
    "    vgg,\n",
    "    GlobalAveragePooling2D(),\n",
    "\n",
    "    Dense(128, activation='relu'),  # Bổ sung tầng Dense để tăng khả năng học\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Dense(num_class, activation='softmax')  # 5 lớp đầu ra\n",
    "])\n",
    "\n",
    "# Biên dịch mô hình\n",
    "model_cnn.compile(\n",
    "    optimizer=Adam(learning_rate=0.001), \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# In tóm tắt mô hình\n",
    "model_cnn.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiến hành train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T10:20:01.400340Z",
     "start_time": "2025-01-12T10:16:02.769858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 184ms/step - accuracy: 0.7551 - loss: 0.7557 - val_accuracy: 0.9986 - val_loss: 0.0110\n",
      "Epoch 2/4\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 155ms/step - accuracy: 0.9941 - loss: 0.0282 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 3/4\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 158ms/step - accuracy: 0.9982 - loss: 0.0121 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 4/4\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 158ms/step - accuracy: 0.9974 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 0.0011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24086a447a0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn.fit(xtrain, ytrain, epochs= 4, validation_data = (xtest, ytest) , batch_size= 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lưu model lại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T10:21:03.899227Z",
     "start_time": "2025-01-12T10:21:03.760363Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model_cnn.save('model/model_cnn.h5', include_optimizer = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('model/model_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
